마르코프 체인(Markov Chain)은 확률 과정의 한 종류로, 현재 상태가 주어졌을 때 미래 상태가 과거 상태와 무관하게 결정되는 특성을 가진다. 이를 **마르코프 성질**(Markov Property)이라고 하며, 다음과 같이 표현할 수 있다.

![[Pasted image 20250312225458.png]]
즉, 현재 상태 Xn이 주어지면, 미래 상태 Xn+1의 확률 분포는 과거 상태들과 관계없이 오직 현재 상태에만 의존한다.

---
### 마르코프 체인의 주요 개념

1. **상태(State) 공간**: 마르코프 체인이 가질 수 있는 모든 상태들의 집합. 상태가 유한하면 **유한 상태 마르코프 체인**, 무한하면 **무한 상태 마르코프 체인**이다.
    
2. **전이 확률(Transition Probability)**: 한 상태에서 다른 상태로 이동할 확률. 보통 **전이 행렬(Transition Matrix)**로 표현된다.
    
    - 전이 행렬 P의 각 원소 Pij는 상태 i에서 상태 j로 이동할 확률을 나타낸다.
3. **정지 상태(Steady-State, Stationary Distribution)**: 시간이 충분히 지났을 때 상태가 일정한 확률 분포를 유지하는 상태.
    
4. **흡수 상태(Absorbing State)**: 한번 도달하면 더 이상 다른 상태로 이동하지 않는 상태.
    
5. **에르고딕(Ergodic) 마르코프 체인**: 모든 상태가 장기적으로 특정한 분포에 수렴하는 성질을 가짐.

![[Pasted image 20250312225733.png]]
