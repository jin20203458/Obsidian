- 마르코프 체인 + 보상
**마르코프 보상 프로세스 (Markov Reward Process, MRP)는 
마르코프 결정 과정 (Markov Decision Process, MDP)의 한 부분으로, 확률적 상태 전이와 보상 시스템**을 포함하는 모델입니다. 주로 **강화 학습**과 관련하여 사용되며, 에이전트가 환경과 상호작용하면서 상태를 전이하고 보상을 얻는 과정을 모델링합니다.

마르코프 보상 프로세스는 **상태(state)**, **전이 확률(transition probability)**, **보상(reward)** 세 가지 주요 요소로 구성됩니다.

### **마르코프 보상 프로세스의 구성 요소**

1. **상태 (State, S)**  
    각 상태는 환경의 특정 상황을 나타냅니다. 예를 들어, 날씨 상태(Sunny, Cloudy, Rainy)나, 로봇이 위치한 공간의 상태일 수 있습니다.
    
2. **전이 확률 (Transition Probability, P)**  
    상태 간 전이는 확률적으로 일어납니다. 상태에서 다른 상태로 전이될 확률을 정의하는 함수입니다. 예를 들어, Sunny에서 Cloudy로 변할 확률, Cloudy에서 Rainy로 변할 확률 등을 말합니다. 일반적으로 **P(s' | s)** 형태로 사용되며, 상태 `s`에서 상태 `s'`로 전이될 확률을 나타냅니다.
    
3. **보상 함수 (Reward Function, R)**  
    각 상태에 대해 주어지는 **보상**을 정의하는 함수입니다. 보상은 에이전트가 특정 상태에 도달했을 때 얻는 값으로, 상태가 좋은지 나쁜지를 평가합니다. 이 보상은 강화 학습에서 **에이전트가 더 나은 행동을 선택할 수 있도록 유도**하는 중요한 요소입니다. 일반적으로 **R(s)로 표현되며, 특정 상태 `s`에서 얻는 보상을 나타냅니다.
    
4. **할인 계수 (Discount Factor, γ)**  
    할인 계수 γ (0 ≤ γ ≤ 1)는 미래의 보상을 얼마나 중요하게 생각할지 결정하는 파라미터입니다. 1에 가까울수록 미래 보상을 현재 보상만큼 중요하게 여깁니다. 0에 가까울수록 미래의 보상은 중요하지 않게 됩니다.

```
#include <iostream>
#include <vector>
#include <cmath>

using namespace std;

// 상태 정의
enum Weather { SUNNY, CLOUDY, RAINY };

// 보상 함수 (각 상태에서 얻을 수 있는 보상)
vector<int> rewards = { 10, 5, -5 };

// 할인 계수 (γ)
const double discountFactor = 0.9;

// 각 상태에서 다음 상태로 전이될 확률 (마르코프 전이 확률)
vector<vector<double>> transitionMatrix = {
    {0.8, 0.1, 0.1},  // SUNNY -> SUNNY, CLOUDY, RAINY
    {0.2, 0.6, 0.2},  // CLOUDY -> SUNNY, CLOUDY, RAINY
    {0.3, 0.3, 0.4}   // RAINY -> SUNNY, CLOUDY, RAINY
};

// 상태 전이 함수 (현재 상태에서 다음 상태를 확률적으로 선택)
Weather getNextState(Weather currentState) {
    double r = static_cast<double>(rand()) / RAND_MAX; // 0.0 ~ 1.0 사이 난수 생성
    double cumulativeProbability = 0.0;

    for (int nextState = 0; nextState < 3; nextState++) 
    {
        cumulativeProbability += transitionMatrix[currentState][nextState];
        if (r <= cumulativeProbability) 
        {
            return static_cast<Weather>(nextState);
        }
    }
    return SUNNY; // 기본 반환 (이론적으로는 도달하지 않음)
}

// 기대 보상 계산 함수 (보상과 할인 계수 적용)
double calculateTotalReward(int steps) {
    double totalReward = 0.0;
    Weather currentState = SUNNY; // 초기 상태 설정

    for (int step = 0; step < steps; step++) {
        // 현재 상태에서 얻을 수 있는 보상
        int reward = rewards[currentState];

        // 할인된 보상 계산 (현재 보상에 할인 계수를 적용)
        totalReward += pow(discountFactor, step) * reward;

        // 다음 상태로 전이
        currentState = getNextState(currentState);
    }

    return totalReward;
}

int main() {
    srand(time(0)); // 랜덤 시드 초기화

    int steps = 10;  // 10단계 동안의 보상 합 계산

    double totalReward = calculateTotalReward(steps);

    cout << "Total expected reward after " << steps << " steps: " << totalReward << endl;

    return 0;
}

```


```
#include <iostream>

using namespace std;

#define NUM_ROOMS 3        // 방 A, B, C
#define GAMMA 0.9          // 할인율
#define THRESHOLD 0.0001   // 수렴 임계값

enum State { A, B, C };    // 상태 정의

// 전이 확률 행렬 (P[s][s'] -> s에서 s'로 이동할 확률)
double transitionMatrix[NUM_ROOMS][NUM_ROOMS] = {
    {0.5, 0.5, 0.0}, // A -> {A, B, C}
    {0.2, 0.6, 0.2}, // B -> {A, B, C}
    {0.1, 0.2, 0.7}  // C -> {A, B, C}
};

// 보상 함수 R(s)
double rewards[NUM_ROOMS] = {
    5,  // A = 5
    -1, // B = -1
    10  // C = 10
};

// 상태 가치 함수 계산
void computeValueFunction(double* V) {
    double delta;
    do {
        delta = 0.0;
        double Vnew[NUM_ROOMS];

        for (int s = 0; s < NUM_ROOMS; s++) {
            double expectedValue = 0.0;

            for (int s_next = 0; s_next < NUM_ROOMS; s_next++) {
                // ∑ P(s'|s) * V(s')
                expectedValue += transitionMatrix[s][s_next] * V[s_next];
            }

            // V(s) = R(s) + γ ∑ P(s'|s) * V(s')
            Vnew[s] = rewards[s] + (GAMMA * expectedValue);

            // 최대 변화량 계산 (수렴 조건 확인)
            delta = max(delta, fabs(Vnew[s] - V[s]));
        }

        // V 값을 업데이트
        for (int i = 0; i < NUM_ROOMS; i++) {
            V[i] = Vnew[i];
        }
    } while (delta > THRESHOLD); // 값이 충분히 수렴할 때까지 반복
}

int main(void) {
    double* V = new double[NUM_ROOMS];
    // 초기 상태 가치 (모두 0으로 시작)
    V[0] = 0.0;
    V[1] = 0.0;
    V[2] = 0.0;

    // 상태 가치 계산
    computeValueFunction(V);

    // 결과 출력
    printf("State Values (V)\n");
    printf("V(A) = %.4f\n", V[A]);
    printf("V(B) = %.4f\n", V[B]);
    printf("V(C) = %.4f\n", V[C]);
    // cout << "State Values (V)\n";
    // cout << "V(A) = " << V[A] << endl;
    // cout << "V(B) = " << V[B] << endl;
    // cout << "V(C) = " << V[C] << endl;

    return 0;
}

```