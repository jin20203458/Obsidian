### **프로세스와 스레드의 개념**

1. **프로그램과 실행**:
    
    - **프로그램**: 디스크에 저장된 정적인 상태의 코드 및 데이터.
    - **프로세스**: 프로그램이 메모리에 적재되어 실행되는 동적인 상태.
        - 메모리의 주요 구성:
            - **코드 영역**: 실행할 명령어가 위치.
            - **데이터 영역**: 전역 변수 및 정적 데이터.
            - **힙 영역**: 동적 메모리 할당을 위한 공간.
            - **스택 영역**: 함수 호출 시의 지역 변수, 매개변수, 리턴 주소를 저장.
2. **프로세스와 스레드의 관계**:
    
    - 하나의 프로세스는 하나 이상의 스레드를 포함할 수 있음.
    - **스레드**는 동일한 프로세스 내의 자원을 공유하며 독립적으로 실행되는 실행 흐름.
        - 공유되는 자원: 코드, 데이터, 힙.
        - 독립적인 자원: 레지스터, 스택.

---
### **운영체제의 관리**

1. **OS와 프로세스 관리**:
    
    - 운영체제는 **프로세스 테이블**을 통해 프로세스를 관리.
    - 프로세스 테이블에는 각 프로세스의 **프로세스 ID (PID)와 PCB**가 저장.
2. **PCB (Process Control Block)**:
    
    - 프로세스를 관리하기 위한 데이터 구조.
    - 프로세스의 전반적인 상태와 자원 정보를 저장:
        - **프로세스 식별 정보**: PID, 부모 프로세스 ID.
        - **프로세스 상태 정보**: 실행 중, 준비 상태, 대기 상태 등.
        - **CPU 상태 정보**: 프로그램 카운터, 레지스터 상태.
        - **메모리 관리 정보**: 코드, 데이터, 스택, 힙의 메모리 주소.
        - **입출력 상태 정보**: 열린 파일 디스크립터, 입출력 장치 정보.
        - **스레드 관리 정보**: 해당 프로세스 내의 모든 TCB 참조.(리스트 또는 테이블)
3. **TCB (Thread Control Block)**:
    
    - 스레드를 관리하기 위한 데이터 구조.
    - 개별 스레드의 실행 상태를 추적:
        - **스레드 ID**: 스레드 고유 식별자.
        - **프로그램 카운터**: 스레드의 다음 명령어 위치.
        - **스택 포인터**: 스레드의 독립적인 스택 상태.
        - **레지스터 정보**: 스레드의 레지스터 상태.
        - **스레드 상태**: 실행 중, 준비 상태, 대기 상태 등.
        - **우선순위 및 스케줄링 정보**: 스케줄링 우선순위, 타임 슬라이스 등.
4. **PCB와 TCB의 관계**:
    
    - **PCB는 해당 프로세스 내의 스레드 정보를 참조**.
    - PCB는 여러 개의 TCB를 참조하는 링크 구조로, 프로세스 내의 모든 스레드를 관리.

---

### **CPU와 실행 단위**

1. **프로세스 vs 스레드**:
    
    - **프로세스**는 운영체제가 관리하는 **추상적인 실행 단위**.
    - **스레드**는 CPU가 처리하는 **실질적인 실행 단위**.
2. **CPU 관점**:
    
    - CPU는 스레드 단위로 작업을 스케줄링하고 실행.
    - CPU는 프로세스 자체에 대한 정보는 알지 못하며, 실행 시점에는 스레드의 상태만 필요.
    - 스레드의 실행 상태는 **TCB**를 통해 관리됨.
3. **컨텍스트 스위칭**:
    
    - **스레드 간** 또는 **프로세스 간** 전환 시 **컨텍스트 스위칭**이 발생.
        - **스레드 간**: 동일한 PCB를 참조하므로 비용이 상대적으로 적음.
        - **프로세스 간**: 다른 PCB로 전환해야 하므로, 캐시 무효화 등 추가 비용 발생.

**개인적인 의견** : 보통 많이 얘기하는 하나의 프로세스 내에 여러 실행흐름(스레드)이 존재한다는 표현보다는 하나의 프로세스가 여러 실행흐름(스레드)를 포함한다. 가 맞는말인것 같다.
**프로세스는 스레드의 컨테이너 역할**

---
### 공유자원 문제

**5개의 스레드가 각각 공유자원에 1을 20000번 더합니다.**

20000  x  5로 100000이 나와야 하지만 그렇지 않다. 왜일까?

- 이러한것을 우리는 데이터 레이스(data race)라고 부름.
- 스레드들간의 컨텍스트 스위칭은 기계어 단위로 이루어짐.
- 스레드는 한 프로세스내의 코드, 데이터, 힙 영역을 공유한다.
- 값을 "읽기만"  한다면 공유자원 문제는 발생하지 않습니다.
```
#include <iostream>
#include <thread>
#include <vector>
#include <mutex>

int sum = 0;  // 공유 자원
//std::mutex mtx;

void add_to_sum(int iterations)
{
	for (int i = 0; i < iterations; ++i)
	{
		//std::lock_guard<std::mutex> lock(mtx); 
		sum += 1;  // 공유 자원에 더하기
	}
}

int main() {
	const int num_threads = 5;
	const int iterations = 20000;
	std::vector<std::thread> threads;

	for (int i = 0; i < num_threads; ++i)
		threads.push_back(std::thread(add_to_sum, iterations));

	for (auto& t : threads)
		t.join();

	std::cout << "Final sum: " << sum << std::endl;  // 결과 출력
	return 0;
}
```

여기서 의문이 들수 있습니다.  어차피 cpu는 결국 연산을 순차적으로 수행할텐데 그럼 sum+=1 이라는 연산도 순차적으로 수행될것 아니냐? 그러면 공유 자원 문제는 왜 일어나는가? 

이는 sum +=1 이 사실 하나의 연산이 아니기 때문에 그렇습니다. +=1 을 어셈블리로 보면 이렇습니다.
```
00007FF7D4371833 mov eax,dword ptr [a]   // eax 레지스터에 a주소 의 값을 로드
00007FF7D4371836 inc eax                 // eax 레지스터의 값을 1증가
00007FF7D4371838 mov dword ptr [a],eax   // eax 레지스터의 값을 a주소에 저장
```

두 스레드가 동시에 a값을 읽어와서 하나씩 증가시키고 대입하면 a의 값은 1밖에 오르지 못할것입니다. 
이것이 우리가 기대하는 각 스레드가 1씩 증가시키는 결과가 나오지 않는 이유입니다.


#### **그럼 이를 해결하기 위해 어떤걸 해야할까요?**
 
 여기서 문제의 발생원인은 한 스레드가 공유자원에 접근하는 동안 다른 스레드 또한 공유자원에 접근하는 것 입니다.
따라서 한 스레드가 공유자원에 접근하는 동안 다른 스레드는 이를 절대 건드릴수 없게 해야합니다. 이를 원자성 이라 합니다.  이를 통해 공유 데이터는 항상 논리적 무결성을 유지하는데
이를 일관성이라고 합니다.

- **원자성**(atomiucity) :  특정 연산이 **중간 상태** 없이 **완전하게 수행되거나, 전혀 수행되지 않아야함**
- **일관성**(consistency) : 데이터는 항상 유효한 상태를 유지해야함

멀티스레드 프로그래밍을 하다보면 이렇게 원자성과 일관성을 유지하는 특수한 조치를 해야 할때가 있습니다. 이러한 조치들을 통칭하여 동기화(synchronize) 라고 합니다. 대표적인것은 임계영역과 뮤텍스, 락 기법입니다.

---

#### Dekker's algorithm
[데커의 알고리즘 - 위키백과, 우리 모두의 백과사전](https://ko.wikipedia.org/wiki/%EB%8D%B0%EC%BB%A4%EC%9D%98_%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98)
데커 알고리즘은 두 프로세스의 동기화를 처리하는 아주 고전적인 알고리즘중 하나입니다.
![[Pasted image 20250114184350.png]]
flag 변수는 본인의 진입의사 표시
turn 변수는 우선권을 나타냅니다.

1. 본인이 임계구역 진입을 위해 본인의 flag변수를 참으로 만듭니다. 
2. 상대의 진입의사를 확인합니다. 상대의 진입의사가 없다면 임계구역에 바로 진입합니다.

3. 상대의 진입의사가 있다면 
   2. 우선권을 확인합니다.
    - 우선권이 상대에게 있을경우 본인의 의사를 철회하고(내 의사가 철회되야 상대방이 임계영역에 진입할수 있기에) 우선권이 본인에게 올때까지 대기합니다.
     (2번째 while), 상대방의 임계구역진입이 끝났다면 turn 변수가 넘어오기에 while문 대기가 끝나고 다시 본인의 의사 표시를 합니다.
     
    - 우선권이 본인에게 있다면 상대방이 자신의 의사를 철회하면 임계구역에 진입합니다.
4. 임계구역에 진입, 본인의 일을 마친다면 우선권을 상대에게 넘기고, 본인의 의사를 철회합니다.

**데커알고리즘은 간단한 원리로 두 프로세스간의 임계영역 문제를 해결하지만 두 프로세스에 한정하고, 방식이 Busy-Waiting 이기에 cpu에 효율적이지 않다는 단점이 있습니다.**
- 생각해보니 turn이 1이고 상대 프로세스의 진입의사도 있지만 상대 프로세스가 어떤이유로 블록되면 본인도 임계구역에 진입할수 없다는 문제또한 있는것 같습니다.

#### Peterson's algorithm
[피터슨의 알고리즘 - 위키백과, 우리 모두의 백과사전](https://ko.wikipedia.org/wiki/%ED%94%BC%ED%84%B0%EC%8A%A8%EC%9D%98_%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98)
![[Pasted image 20250114192104.png]]

1. 본인의 진입 의사 표현을 합니다
2. 상대에게 먼저 우선권을 줍니다.
3. 상대의 진입의사가 있다면 대기합니다, 없다면 임계구역에 진입합니다.

4. 임계구역에 진입해서 할일을 했다면 의사를 철회합니다. 

**피터슨 알고리즘은 데커알고리즘과 같은 단점을 공유하지만 훨씬 직관적이고 알기 쉽다는 장점이 있는것 같습니다.**

**우리는 고전적인 동기화 알고리즘은 데커 알고리즘과 피터슨 알고리즘을 알아보았습니다.**
**두 알고리즘은 임계영역 문제를 직관적으로 알아볼수 있어서 매우 좋은 교제가 되지만**

turn변수와 flag변수의 원자성이 보장되어야한다, cpu의 Instruction Reordering(명령어 재정렬)같은 최적화 과정에서 알고리즘이 비정상 작동할수 있다는 조건과
cpu가 계속 의사를 체크해야하는 방식의 비효율성 때문에 현대에서는 대부분 사용되지 않습니다.


----
#### mutex (mutual exclusion: 상호배제)
[[thread.mutex.requirements.mutex.general]](https://timsong-cpp.github.io/cppwp/n4950/thread.mutex.requirements.mutex.general)
위 5개의 스레드 더하기 문제에서 주석처리된 내용이 바로 mutex입니다.  
```
  constexpr _Mutex_base(int _Flags = 0) noexcept {
      _Mtx_storage._Critical_section = {};
      _Mtx_storage._Thread_id        = -1;
      _Mtx_storage._Type             = _Flags | _Mtx_try;
      _Mtx_storage._Count            = 0;
```
- **뮤텍스를 잠근 스레드만** 공유 자원에 접근할 수 있습니다.
- 다른 스레드가 동일한 뮤텍스를 잠그려 할 경우, **뮤텍스가 해제될 때까지 블록(block)** 됩니다.
*블록된 뮤텍스가 여럿일때 공유자원이 해제되면 누가먼저 접근하는가?*
- 대부분 FIFO(FirstInFirstOut)를 따름, 다만 OS 스케줄러에 따라 바뀔수 있다.


뮤텍스가 너무 크다면 싱글스레드와 다름이 없고, 너무 작다면 복잡성이 커지며 데드락 문제를 야기할수있다.(적당한 단위가 중요)

#### Semaphore

세마포(Semaphore)는 스레드 간의 동기화를 위해 사용하는 객체로, **자원에 접근할 수 있는 스레드의 수**를 제한합니다. `wait()` 또는 `acquire()`로 자원을 요청하고, 세마포 값이 0이면 대기 상태에 들어갑니다. `release()`는 세마포 값을 증가시키며 대기 중인 스레드를 깨우는 역할을 합니다.

세마포는 값이 0,1로 제한되는 Binary Semaphore와 Counting Semaphore가 있는데 전자의 경우 뮤텍스와 비슷하게 동작합니다..  우리가 생각하는 일반적 세마포는 후자에 가깝습니다.

```
_EXPORT_STD using binary_semaphore = counting_semaphore<1>;
```
- 이진 세마포는 결국 크기가 1인카운팅 세마포의 별칭입니다.


- **P 연산 (Wait/Down)**
    - 세마포의 값을 감소시킵니다.
    - 세마포 값이 **0보다 크다면 자원 접근을 허용**합니다.
    - 값이 0이면 스레드는 대기 상태가 됩니다.
- **V 연산 (Signal/Up)**
    - 세마포의 값을 증가시킵니다.
    - 대기 중인 스레드가 있다면, 대기 스레드 중 하나를 **깨웁니다**.

#### std::semaphore 구현

- **`wait`**는 호출된 스레드를 대기 상태로 만든다.
- **`notify_one`**는 대기 중인 스레드 중 하나를 깨운다.
- **`notify_all`**은 대기 중인 모든 스레드를 깨운다.


**결론**
뮤텍스는 하나의 공유자원에 하나의 스레드의 접근만을 보장하는 동기화 도구이며,
세마포는 하나의 공유 자원에 대해 여러 스레드가 동시에 접근할 수 있는지 조정할 수 있는 동기화 도구입니다.
- 블록된 스레드들은 대기큐에 저장되어있다가 OS의 방침에따라 처리됩니다.


####  Critical Section
[Critical Section Objects - Win32 apps | Microsoft Learn](https://learn.microsoft.com/en-us/windows/win32/Sync/critical-section-objects)
A _critical section object_ provides synchronization similar to that provided by a mutex object, except that a critical section can be used only by the threads of a single process. Critical section objects cannot be shared across processes.
```
InitializeCriticalSectionAndSpinCount(&cs, 4000);/객체 초기화, 스핀카운트 설정

    EnterCriticalSection(&cs); // CRITICAL_SECTION 잠금
     
    sharedResource++;           // 공유 자원에 1을 더하는 연산

    LeaveCriticalSection(&cs);  // CRITICAL_SECTION 잠금 해제
```

크리티컬 섹션은 **유저 모드**에서만 작동하는 동기화 객체로, **하나의 프로세스 내 스레드들 간의 동기화**를 빠르고 효율적으로 처리합니다. **커널 모드를 거치지 않기 때문에 성능상 이점이 있지만, 다른 프로세스와의 동기화는 지원하지 않습니다.**

```
typedef struct _RTL_CRITICAL_SECTION {
    PRTL_CRITICAL_SECTION_DEBUG DebugInfo;
    LONG LockCount;       // 잠금 횟수(0:잠금x,-1:잠금,대기중인 스레드0,-2:잠금, 대기중                               인 스레드 1(대기중인 스레드가 생길때마다 추가))
    LONG RecursionCount;  // 재귀적 잠금 횟수 
    HANDLE OwningThread;  // 크리티컬 섹션을 소유한 스레드
    HANDLE LockSemaphore; // 대기 중인 스레드가 사용할 세마포어 핸들
    ULONG_PTR SpinCount;  // 스핀락을 사용할 횟수
} RTL_CRITICAL_SECTION, *PRTL_CRITICAL_SECTION;
```
![[Pasted image 20250119182724.png]]

**여기서부턴 제 생각입니다.**
CriticalSection 객체는 하나의 프로세스 내 스레드를 빠르게 처리하기 위해서 스핀락을 도입한? 뮤텍스 라고 생각됩니다.  스핀 카운트가 없을때는 뮤텍스와 거의 동일하게(커널 영역에서) 작동하지만 스핀 카운트 동안 스레드가 busy wait 상태로 대기합니다. 이러한 방식으로 스핀락의 장점만 취하고 단점을 날려버린? 동기화 객체라고 생각됩니다. 
 ### WaitOnAddress

### 추가 
위 설명에서 스핀카운트가 끝난 이후에는 세마포어를 사용해서 동기화를 한다고 적혀있습니다. 이는  Window XP, Vista, 7 까지에 한하고 Window 8 부터는 더 가벼운 사용자 모드 대기 메커니즘인 **WaitOnAddress**가 도입되어 (크리티컬 섹션을 사용하는 이유를 생각해 보시길 바랍니다.)
, 크리티컬 섹션의 내부 구현이 세마포어 기반에서 WaitOnAddress를 사용하는 방식으로 변경되었습니다.


[WaitOnAddress function (synchapi.h) - Win32 apps | Microsoft Learn](https://learn.microsoft.com/en-us/windows/win32/api/synchapi/nf-synchapi-waitonaddress)

**WaitOnAddress**  는 RtlEnterCriticalSection의 함수 내부에서 호출한다고 추측하며  확인할수는 없었습니다.
```
00007FF8A06FFADD  call        RtlpEnterCriticalSectionContended (07FF8A06FFAF0h)  
00007FF8A06FFAE2  jmp         RtlEnterCriticalSection+26h (07FF8A06FFAC6h)  
00007FF8A06FFAE4  int         3  
.
.
```
### WaitOnAddress function (synchapi.h)
WaitOnAddress 함수는 스레드 동기화에 사용되는 중요한 API로, 특정 메모리 주소의 값이 변경될 때까지 스레드를 대기 상태로 유지합니다. 이 함수는 효율적인 스레드 간 통신을 가능하게 하며, 특히 다중 스레드 환경에서 유용합니다.
```
BOOL WaitOnAddress(
  [in]           volatile VOID *Address,       // 기다릴 메모리 주소
  [in]           PVOID         CompareAddress, // 비교할 값 
  [in]           SIZE_T        AddressSize,    // 크기
  [in, optional] DWORD         dwMilliseconds  // 대기시간(`INFINITE`이면 무제한)
);
```

- 값이 다르면 즉이 반환
- 값이 달라지면 자동 반환
- WakeByAddressSingle이나 WakeByAddressAll을 사용하여 스레드를 깨울수 있음
- `WaitOnAddress`는 스레드 스케줄러를 방해하지 않으므로, 루프 내에서 `Sleep` 함수를 사용하는 것보다 효율적 


?????
1. 스레드 스케줄러를 방해하지 않는다고 했음으로 커널과는 완전 별개의 동기화 방법이다.. ?
2. 그렇다면 해당 블록된 스레드들은 어떻게 관리하지?
3. 특정 메모리 주소의 값이 변경되는건 어떤식으로 확인하지? 커널의 도움? 이것또한 유저영역에  진행?

해당함수는 커널 모드로 진입하지 않고, 유저모드에서 대기하기에 더욱 신속한 동기화를 지원하는 도구입니다.

---

cpu 코어는 여러개라도 결국 하나의 메모리에 접근, 이시간을 메모리 바운드 시간이라함, (이때 cpu개수보다 더 적은수의 cpu로 처리됨, 단 풀링분류를 기준으로 다중 데이터구조를 지원하지 않는 컴퓨터에 한함)


이벤트 : 잠자는 스레드를 깨우는 도구
- Reset : 이벤트가 없음 0
- Set : 이벤트가 있음 1

- **자동 이벤트 (Auto-Reset Event)**: 이벤트가 신호 상태가 되면 대기 중인 하나의 스레드만 깨우고 자동으로 비신호 상태로 전환되는 동기화 도구.
- **수동 이벤트 (Manual-Reset Event)**: 이벤트가 신호 상태가 되면 대기 중인 모든 스레드를 깨우고, 명시적으로 비신호 상태로 전환될 때까지 유지되는 동기화 도구.

- CreateEvent(): 이벤트 생성
- CloseHandle(): 이벤트 파괴
- WaitForSingleObject: 이벤트 대기
- SetEvent(): 이벤트에 신호를 줌

---

#### 원자조작

- 더이상 쪼갤수 없는 연산의 단위
우리는 위 +=1이 3개의 복합적인 연산이기에 데이터 레이스가 발생한다고 배웠습니다. 원자조작(atomic operation)은 이러한 연산이 한 스레드씩만 처리됨을 보장합니다. 
말 그대로 +=1 이라는 연산이 처리될때 완전히 완료되거나 완료되지 않거나 하나의 상태만을 가지는 것입니다. (부분적으로 실행되거나 타 작업과 혼합되지 않음)

```
#include <atomic>
#include <iostream>

int main() {
    std::atomic<int> a(0);

    // 원자적 덧셈 연산
    a.fetch_add(3);  // a는 3만큼 증가합니다.

    std::cout << "a = " << a.load() << std::endl;  // a의 값을 출력합니다.

    return 0;
}
```
fetch_add() 함수는 window 환경에서 _InterlockedExchangeAdd(&counter, value); 라는 함수를 내부적으로 호출하는데 해당 함수는 `Addend`에 있는 값을 원자적으로 `Value`만큼 증가시키며, 그 이전 값을 반환합니다. 

```
LONG64 InterlockedExchangeAdd64(
  [in, out] LONG64 volatile *Addend,
  [in]      LONG64          Value
);
```

[InterlockedExchangeAdd64 함수(winnt.h) - Win32 앱 | 마이크로소프트 런](https://learn.microsoft.com/en-us/windows/win32/api/winnt/nf-winnt-interlockedexchangeadd64)
전체 작업에 barrier or **fence**를 설정하여 작업의 원자성을 보장하는 원리

```
  long _Result; _ATOMIC_CHOOSE_INTRINSIC(static_cast<unsigned int>(_Order), _Result, _InterlockedExchangeAdd, 
00007FF634002549 mov ecx,dword ptr [_Order] 
00007FF63400254F call _Check_memory_order (07FF6340010DCh) 
00007FF634002554 nop 
00007FF634002555 mov rcx,qword ptr [this] 
00007FF63400255C call 
std::_Atomic_address_as<long,std::_Atomic_padded<int> > (07FF6340010E1h) 00007FF634002561 mov ecx,dword ptr [_Operand] 
00007FF634002567 lock xadd dword ptr [rax],ecx 
00007FF63400256B mov eax,ecx 
00007FF63400256D mov dword ptr [_Result],eax
```
fetch add 의 어셈블리 입니다.
[Intel® 64 and IA-32 Architectures Software Developer’s Manual](https://software.intel.com/content/www/us/en/develop/articles/intel-sdm.html)

Causes the processor's LOCK# signal to be asserted during execution of the accompanying instruction (turns the instruction into an atomic instruction). In a multiprocessor environment, the LOCK# signal ensures that the processor has exclusive use of any shared memory while the signal is asserted.

.잠금의 전염성

#### 컴파일러 베리어
 
컴파일러 배리어는 **소프트웨어 수준**에서 컴파일러의 최적화
- 명령어 재배치, 루프 언롤링 등..

로 인한 명령어 순서 변경을 방지하는 기능입니다.
단 이는 소스코드의 순서 변경을 막는것이기에 각 CPU코어가 독립적으로 동작하는 **멀티 코어 환경에서 컴파일러 배리어만으로는 충분히 순서를 보장할 수 없습니다.**

#### 메모리 베리어

메모리 베리어는 주로 **메모리 접근의 순서**를 보장하는 데 사용됩니다. 병렬 시스템에서 **다중 프로세서**가 동시에 메모리에 접근할 때, 메모리의 **일관성**을 유지하기 위해 메모리 연산의 순서를 제어할 필요가 있습니다. 이는 **하드웨어**와 **소프트웨어** 간의 동기화를 보장하고, **동시성 문제**를 방지하는 데 중요한 역할을 합니다.

멀티코어 시스템에서는 각 코어가 독립적으로 동작하며, 각 코어마다 **로컬 캐시**를 가지고 있기 때문에 **메모리 일관성** 문제가 발생할 수 있습니다. 예를 들어, 한 코어에서 메모리에 값을 쓴 후, 다른 코어에서 그 값을 읽으려 할 때, **캐시 동기화 문제**로 인해 최신 값이 읽히지 않을 수 있습니다.

또한, **컴파일러**나 **프로세서**가 최적화 과정에서 명령어 순서를 변경할 수 있기 때문에, 프로그래머가 의도한 순서대로 명령어가 실행되도록 보장하는 것이 중요합니다.

- **Full Barrier (전체 베리어)**:
    - 읽기와 쓰기 순서를 모두 제어합니다.
    - **Load**(읽기) 명령어가 **Store**(쓰기) 명령어 후에 실행되도록 보장합니다.
    - 예를 들어, `Store x; FullBarrier(); Load y;`는 `Store x`가 **완전히 완료**된 후에 `Load y`가 실행되도록 보장합니다.

- **Load-Load Barrier**:
    - 여러 **읽기** 연산 간의 순서를 보장합니다.
    - 예를 들어, `Load a; Load b; Load-LoadBarrier(); Load c;`에서, `Load c`가 `Load a`와 `Load b`보다 먼저 실행되지 않도록 보장합니다.

- **Store-Store Barrier**:
    - 여러 **쓰기** 연산 간의 순서를 보장합니다.
    - 예를 들어, `Store a; Store b; Store-StoreBarrier(); Store c;`에서, `Store c`가 `Store a`와 `Store b`보다 먼저 실행되지 않도록 보장합니다.

- **Load-Store Barrier**:
    - 읽기 연산과 쓰기 연산 간의 순서를 보장합니다.
    - 예를 들어, `Load x; Store y; Load-StoreBarrier(); Load z;`에서, `Store y`가 `Load x` 이후에 실행되도록 보장합니다.

메모리 베리어는 메모리 연산의 순서를 보장하는 것으로 각 코어의 로컬캐시는 관여하지 않습니다.
캐시 동기화는 MESI프로토콜을 사용합니다. [[캐시 계층 구조와 캐시 일관성 프로토콜]]
