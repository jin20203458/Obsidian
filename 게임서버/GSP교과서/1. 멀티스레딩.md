### **프로세스와 스레드의 개념**

1. **프로그램과 실행**:
    
    - **프로그램**: 디스크에 저장된 정적인 상태의 코드 및 데이터.
    - **프로세스**: 프로그램이 메모리에 적재되어 실행되는 동적인 상태.
        - 메모리의 주요 구성:
            - **코드 영역**: 실행할 명령어가 위치.
            - **데이터 영역**: 전역 변수 및 정적 데이터.
            - **힙 영역**: 동적 메모리 할당을 위한 공간.
            - **스택 영역**: 함수 호출 시의 지역 변수, 매개변수, 리턴 주소를 저장.
2. **프로세스와 스레드의 관계**:
    
    - 하나의 프로세스는 하나 이상의 스레드를 포함할 수 있음.
    - **스레드**는 동일한 프로세스 내의 자원을 공유하며 독립적으로 실행되는 실행 흐름.
        - 공유되는 자원: 코드, 데이터, 힙.
        - 독립적인 자원: 레지스터, 스택.

---
### **운영체제의 관리**

1. **OS와 프로세스 관리**:
    
    - 운영체제는 **프로세스 테이블**을 통해 프로세스를 관리.
    - 프로세스 테이블에는 각 프로세스의 **프로세스 ID (PID)와 PCB**가 저장.
2. **PCB (Process Control Block)**:
    
    - 프로세스를 관리하기 위한 데이터 구조.
    - 프로세스의 전반적인 상태와 자원 정보를 저장:
        - **프로세스 식별 정보**: PID, 부모 프로세스 ID.
        - **프로세스 상태 정보**: 실행 중, 준비 상태, 대기 상태 등.
        - **CPU 상태 정보**: 프로그램 카운터, 레지스터 상태.
        - **메모리 관리 정보**: 코드, 데이터, 스택, 힙의 메모리 주소.
        - **입출력 상태 정보**: 열린 파일 디스크립터, 입출력 장치 정보.
        - **스레드 관리 정보**: 해당 프로세스 내의 모든 TCB 참조.(리스트 또는 테이블)
3. **TCB (Thread Control Block)**:
    
    - 스레드를 관리하기 위한 데이터 구조.
    - 개별 스레드의 실행 상태를 추적:
        - **스레드 ID**: 스레드 고유 식별자.
        - **프로그램 카운터**: 스레드의 다음 명령어 위치.
        - **스택 포인터**: 스레드의 독립적인 스택 상태.
        - **레지스터 정보**: 스레드의 레지스터 상태.
        - **스레드 상태**: 실행 중, 준비 상태, 대기 상태 등.
        - **우선순위 및 스케줄링 정보**: 스케줄링 우선순위, 타임 슬라이스 등.
4. **PCB와 TCB의 관계**:
    
    - **PCB는 해당 프로세스 내의 스레드 정보를 참조**.
    - PCB는 여러 개의 TCB를 참조하는 링크 구조로, 프로세스 내의 모든 스레드를 관리.

---

### **CPU와 실행 단위**

1. **프로세스 vs 스레드**:
    
    - **프로세스**는 운영체제가 관리하는 **추상적인 실행 단위**.
    - **스레드**는 CPU가 처리하는 **실질적인 실행 단위**.
2. **CPU 관점**:
    
    - CPU는 스레드 단위로 작업을 스케줄링하고 실행.
    - CPU는 프로세스 자체에 대한 정보는 알지 못하며, 실행 시점에는 스레드의 상태만 필요.
    - 스레드의 실행 상태는 **TCB**를 통해 관리됨.
3. **컨텍스트 스위칭**:
    
    - **스레드 간** 또는 **프로세스 간** 전환 시 **컨텍스트 스위칭**이 발생.
        - **스레드 간**: 동일한 PCB를 참조하므로 비용이 상대적으로 적음.
        - **프로세스 간**: 다른 PCB로 전환해야 하므로, 캐시 무효화 등 추가 비용 발생.

**개인적인 의견** : 보통 많이 얘기하는 하나의 프로세스 내에 여러 실행흐름(스레드)이 존재한다는 표현보다는 하나의 프로세스가 여러 실행흐름(스레드)를 포함한다. 가 맞는말인것 같다.
**프로세스는 스레드의 컨테이너 역할**

---
### 공유자원 문제

**5개의 스레드가 각각 공유자원에 1을 20000번 더합니다.**

20000  x  5로 100000이 나와야 하지만 그렇지 않다. 왜일까?

- 이러한것을 우리는 데이터 레이스(data race)라고 부름.
- 스레드들간의 컨텍스트 스위칭은 기계어 단위로 이루어짐.
- 스레드는 한 프로세스내의 코드, 데이터, 힙 영역을 공유한다.
- 값을 "읽기만"  한다면 공유자원 문제는 발생하지 않습니다.
```
#include <iostream>
#include <thread>
#include <vector>
#include <mutex>

int sum = 0;  // 공유 자원
//std::mutex mtx;

void add_to_sum(int iterations)
{
	for (int i = 0; i < iterations; ++i)
	{
		//std::lock_guard<std::mutex> lock(mtx); 
		sum += 1;  // 공유 자원에 더하기
	}
}

int main() {
	const int num_threads = 5;
	const int iterations = 20000;
	std::vector<std::thread> threads;

	for (int i = 0; i < num_threads; ++i)
		threads.push_back(std::thread(add_to_sum, iterations));

	for (auto& t : threads)
		t.join();

	std::cout << "Final sum: " << sum << std::endl;  // 결과 출력
	return 0;
}
```

여기서 의문이 들수 있습니다.  어차피 cpu는 결국 연산을 순차적으로 수행할텐데 그럼 sum+=1 이라는 연산도 순차적으로 수행될것 아니냐? 그러면 공유 자원 문제는 왜 일어나는가? 

이는 sum +=1 이 사실 하나의 연산이 아니기 때문에 그렇습니다. +=1 을 어셈블리로 보면 이렇습니다.
```
00007FF7D4371833 mov eax,dword ptr [a]   // eax 레지스터에 a주소 의 값을 로드
00007FF7D4371836 inc eax                 // eax 레지스터의 값을 1증가
00007FF7D4371838 mov dword ptr [a],eax   // eax 레지스터의 값을 a주소에 저장
```

두 스레드가 동시에 a값을 읽어와서 하나씩 증가시키고 대입하면 a의 값은 1밖에 오르지 못할것입니다. 
이것이 우리가 기대하는 각 스레드가 1씩 증가시키는 결과가 나오지 않는 이유입니다.


#### **그럼 이를 해결하기 위해 어떤걸 해야할까요?**
 
 여기서 문제의 발생원인은 한 스레드가 공유자원에 접근하는 동안 다른 스레드 또한 공유자원에 접근하는 것 입니다.
따라서 한 스레드가 공유자원에 접근하는 동안 다른 스레드는 이를 절대 건드릴수 없게 해야합니다. 이를 원자성 이라 합니다.  이를 통해 공유 데이터는 항상 논리적 무결성을 유지하는데
이를 일관성이라고 합니다.

- **원자성**(atomiucity) :  특정 연산이 **중간 상태** 없이 **완전하게 수행되거나, 전혀 수행되지 않아야함**
- **일관성**(consistency) : 데이터는 항상 유효한 상태를 유지해야함

멀티스레드 프로그래밍을 하다보면 이렇게 원자성과 일관성을 유지하는 특수한 조치를 해야 할때가 있습니다. 이러한 조치들을 통칭하여 동기화(synchronize) 라고 합니다. 대표적인것은 임계영역과 뮤텍스, 락 기법입니다.

---

#### Dekker's algorithm
[데커의 알고리즘 - 위키백과, 우리 모두의 백과사전](https://ko.wikipedia.org/wiki/%EB%8D%B0%EC%BB%A4%EC%9D%98_%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98)
데커 알고리즘은 두 프로세스의 동기화를 처리하는 아주 고전적인 알고리즘중 하나입니다.
![[Pasted image 20250114184350.png]]
flag 변수는 본인의 진입의사 표시
turn 변수는 우선권을 나타냅니다.

1. 본인이 임계구역 진입을 위해 본인의 flag변수를 참으로 만듭니다. 
2. 상대의 진입의사를 확인합니다. 상대의 진입의사가 없다면 임계구역에 바로 진입합니다.

3. 상대의 진입의사가 있다면 
   2. 우선권을 확인합니다.
    - 우선권이 상대에게 있을경우 본인의 의사를 철회하고(내 의사가 철회되야 상대방이 임계영역에 진입할수 있기에) 우선권이 본인에게 올때까지 대기합니다.
     (2번째 while), 상대방의 임계구역진입이 끝났다면 turn 변수가 넘어오기에 while문 대기가 끝나고 다시 본인의 의사 표시를 합니다.
     
    - 우선권이 본인에게 있다면 상대방이 자신의 의사를 철회하면 임계구역에 진입합니다.
4. 임계구역에 진입, 본인의 일을 마친다면 우선권을 상대에게 넘기고, 본인의 의사를 철회합니다.

**데커알고리즘은 간단한 원리로 두 프로세스간의 임계영역 문제를 해결하지만 두 프로세스에 한정하고, 방식이 Busy-Waiting 이기에 cpu에 효율적이지 않다는 단점이 있습니다.**
- 생각해보니 turn이 1이고 상대 프로세스의 진입의사도 있지만 상대 프로세스가 어떤이유로 블록되면 본인도 임계구역에 진입할수 없다는 문제또한 있는것 같습니다.

#### Peterson's algorithm
[피터슨의 알고리즘 - 위키백과, 우리 모두의 백과사전](https://ko.wikipedia.org/wiki/%ED%94%BC%ED%84%B0%EC%8A%A8%EC%9D%98_%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98)
![[Pasted image 20250114192104.png]]

1. 본인의 진입 의사 표현을 합니다
2. 상대에게 먼저 우선권을 줍니다.
3. 상대의 진입의사가 있다면 대기합니다, 없다면 임계구역에 진입합니다.

4. 임계구역에 진입해서 할일을 했다면 의사를 철회합니다. 

**피터슨 알고리즘은 데커알고리즘과 같은 단점을 공유하지만 훨씬 직관적이고 알기 쉽다는 장점이 있는것 같습니다.**

**우리는 고전적인 동기화 알고리즘은 데커 알고리즘과 피터슨 알고리즘을 알아보았습니다.**
**두 알고리즘은 임계영역 문제를 직관적으로 알아볼수 있어서 매우 좋은 교제가 되지만**

turn변수와 flag변수의 원자성이 보장되어야한다, cpu의 Instruction Reordering(명령어 재정렬)같은 최적화 과정에서 알고리즘이 비정상 작동할수 있다는 조건과
cpu가 계속 의사를 체크해야하는 방식의 비효율성 때문에 현대에서는 대부분 사용되지 않습니다.


----

#### mutex (mutual exclusion: 상호배제)
위 5개의 스레드 더하기 문제에서 주석처리된 내용이 바로 mutex입니다.  

- **뮤텍스를 잠근 스레드만** 공유 자원에 접근할 수 있습니다.
- 다른 스레드가 동일한 뮤텍스를 잠그려 할 경우, **뮤텍스가 해제될 때까지 블록(block)** 됩니다.
*블록된 뮤텍스가 여럿일때 공유자원이 해제되면 누가먼저 접근하는가?*
- 대부분 FIFO(FirstInFirstOut)를 따름, 다만 OS 스케줄러에 따라 바뀔수 있다.


뮤텍스가 너무 크다면 싱글스레드와 다름이 없고, 너무 작다면 복잡성이 커지며 데드락 문제를 야기할수있다.(적당한 단위가 중요)

#### Semaphore

세마포(Semaphore)는 스레드 간의 동기화를 위해 사용하는 객체로, **자원에 접근할 수 있는 스레드의 수**를 제한합니다. `wait()` 또는 `acquire()`로 자원을 요청하고, 세마포 값이 0이면 대기 상태에 들어갑니다. `release()`는 세마포 값을 증가시키며 대기 중인 스레드를 깨우는 역할을 합니다.

세마포는 값이 0,1로 제한되는 Binary Semaphore와 Counting Semaphore가 있는데 전자의 경우 뮤텍스와 비슷하게 동작합니다..  우리가 생각하는 일반적 세마포는 후자에 가깝습니다.

- **P 연산 (Wait/Down)**
    - 세마포의 값을 감소시킵니다.
    - 세마포 값이 **0보다 크다면 자원 접근을 허용**합니다.
    - 값이 0이면 스레드는 대기 상태가 됩니다.
- **V 연산 (Signal/Up)**
    - 세마포의 값을 증가시킵니다.
    - 대기 중인 스레드가 있다면, 대기 스레드 중 하나를 **깨웁니다**.

**결론**
뮤텍스는 하나의 공유자원에 하나의 스레드의 접근만을 보장하는 동기화 도구이며,
세마포는 하나의 공유 자원에 대해 여러 스레드가 동시에 접근할 수 있는지 조정할 수 있는 동기화 도구입니다.
- 블록된 스레드들은 대기큐에 저장되어있다가 OS의 방침에따라 처리됩니다.

---

cpu 코어는 여러개라도 결국 하나의 메모리에 접근, 이시간을 메모리 바운드 시간이라함, (이때 cpu개수보다 더 적은수의 cpu로 처리됨, 단 풀링분류를 기준으로 다중 데이터구조를 지원하지 않는 컴퓨터에 한함)


이벤트 : 잠자는 스레드를 깨우는 도구
- Reset : 이벤트가 없음 0
- Set : 이벤트가 있음 1

- **자동 이벤트 (Auto-Reset Event)**: 이벤트가 신호 상태가 되면 대기 중인 하나의 스레드만 깨우고 자동으로 비신호 상태로 전환되는 동기화 도구.
- **수동 이벤트 (Manual-Reset Event)**: 이벤트가 신호 상태가 되면 대기 중인 모든 스레드를 깨우고, 명시적으로 비신호 상태로 전환될 때까지 유지되는 동기화 도구.

- CreateEvent(): 이벤트 생성
- CloseHandle(): 이벤트 파괴
- WaitForSingleObject: 이벤트 대기
- SetEvent(): 이벤트에 신호를 줌

---

#### 원자조작

우리는 위 +=1이 3개의 복합적인 연산이기에 데이터 레이스가 발생한다고 배웠습니다. 원자조작(atomic operation)은 이러한 연산이 한 스레드씩만 처리됨을 보장합니다. 
말 그대로 +=1 이라는 연산이 처리될때 완전히 완료되거나 완료되지 않거나 하나의 상태만을 가지는 것입니다. (부분적으로 실행되거나 타 작업과 혼합되지 않음)

```
#include <atomic>
#include <iostream>

int main() {
    std::atomic<int> a(0);

    // 원자적 덧셈 연산
    a.fetch_add(3);  // a는 3만큼 증가합니다.

    std::cout << "a = " << a.load() << std::endl;  // a의 값을 출력합니다.

    return 0;
}
```
fetch_add() 함수는 window 환경에서 _InterlockedExchangeAdd(&counter, value); 라는 함수를 내부적으로 호출하는데 해당 함수는 `Addend`에 있는 값을 원자적으로 `Value`만큼 증가시키며, 그 이전 값을 반환합니다. 

```
LONG64 InterlockedExchangeAdd64(
  [in, out] LONG64 volatile *Addend,
  [in]      LONG64          Value
);
```

[InterlockedExchangeAdd64 함수(winnt.h) - Win32 앱 | 마이크로소프트 런](https://learn.microsoft.com/en-us/windows/win32/api/winnt/nf-winnt-interlockedexchangeadd64)
원리가 자세히 적혀있진 않은데 전체 작업에 barrier or **fence**를 설정하여 작업의 원자성을 보장하는 원리인것 같습니다.

피터슨ㄴ 알고리즘

잠금의 전염성

dynamic priority boosting윈도우의 우선순위

윈도우 환경에서의 크리티컬 섹션

유저영역 동기화 객체와 커널동기화 객체의 차이점